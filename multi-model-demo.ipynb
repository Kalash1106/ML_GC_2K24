{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71608,"databundleVersionId":7895811,"sourceType":"competition"},{"sourceId":7851874,"sourceType":"datasetVersion","datasetId":4602625}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/Kalash1106/ML_GC_2K24","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working/ML_GC_2K24","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\n# Opening JSON file\nf = open('config.json')\nparams = json.load(f)\n\nparams","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### assign PARAMS ###\nparams['train_image_folder'] = \"/kaggle/input/aiml-general-championship/KCDH2024_Training_Input_10K/KCDH2024_Training_Input_10K\"\nparams['gt_file'] = \"/kaggle/working/ML_GC_2K24/data/KCDH2024_Training_GroundTruth.csv\"\nparams['mapping_file'] = \"/kaggle/working/ML_GC_2K24/utility/disease_id.json\"\n\nparams['eval_image_folder'] = \"/kaggle/input/aiml-general-championship/KCDH2024_Test_Input/KCDH2024_Test_Input\"\nparams['eval_labels'] = \"/kaggle/working/ML_GC_2K24/data/eval_labels.csv\"\nparams['train_batch_size'] = 64\n\nparams","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport pandas as pd\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import recall_score\n\nimport torch\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nfrom torchvision import models\nfrom torchvision import transforms\n\n# from PIL import Image\n# from tqdm import tqdm\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from multimodel_pipeline import Classify, CustomDataset, get_splits, train_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mappings = {\n    \"MEL\": 0,\n    \"NV\": 1,\n    \"BCC\": 0,\n    \"AKIEC\": 0,\n    \"BKL\": 0,\n    \"DF\" : 0,\n    \"VASC\" : 0\n  }\ninv_mappings = {\n    0:\"OTHER\",\n    1:\"NV\",\n}\ngt_file = '/kaggle/working/ML_GC_2K24/data/KCDH2024_Training_GroundTruth.csv'\n\n\nclass_obj = Classify(mappings, inv_mappings, gt_file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### Define Model Based on NUM_CLASSES #######\nNUM_CLASSES = class_obj.num_classes\n\n#resnet 34 model\n# model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT) \n\n#resnet 18 model with xavier\n# model = models.resnet18(weights=None)\n# num_features = model.fc.in_features\n# model.fc = torch.nn.Linear(num_features, NUM_CLASSES)\n# torch.nn.init.xavier_uniform_(model.fc.weight)\n\n#pretrained model loading for further training\ncheckpoint = torch.load('/kaggle/input/resnet-weights/checkpoint (4).pth') # path of .pth file\nmodel = checkpoint['model']\nmodel.load_state_dict(checkpoint['weights']['last_weights']) #loading the last epoch weights\n\n#model parameters\nprint(\"Total parameters:\", sum(p.numel() for p in model.parameters()), \n      \", Trainable parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad), \n      \", Non-trainable parameters:\", sum(p.numel() for p in model.parameters() if not p.requires_grad))\nprint()\n\n\n##### Defining Dataset and Dataloader ######\nNUM_WORKERS = 4\n\ntrain_df, val_df = get_splits(class_obj.clean_df, params['test_size'], stratify=True)\ntest_df = pd.read_csv(params['eval_labels'], header=None).rename(columns={0: 'image'})\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(p=0.2),\n    transforms.RandomRotation(degrees=20),\n    transforms.RandomChoice([\n            transforms.RandomPerspective(0.5, 0.5),\n            transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n            transforms.ElasticTransform(alpha=20.0, sigma=5.0)\n        ], p=[0.3, 0.1, 0.2]),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n#     model_preprocess,\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n#     model_preprocess,\n])\n\ntrain_ds = CustomDataset(dataframe=train_df, root_dir=params['train_image_folder'], transform=train_transform)\nval_ds = CustomDataset(dataframe=val_df, root_dir=params['train_image_folder'], transform=val_transform)\ntest_ds = CustomDataset(dataframe=test_df, root_dir=params['eval_image_folder'], transform=val_transform, is_test=True)\n\n# Create DataLoader with prefetch and pin memory\ntrain_dl = DataLoader(train_ds, batch_size=params['train_batch_size'], shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size=params['test_batch_size'], shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\ntest_dl = DataLoader(test_ds, batch_size=params['eval_batch_size'], shuffle=False, num_workers=NUM_WORKERS, pin_memory=False)\nprint()\nprint(f\"train_dl batch shape: input- {next(iter(train_dl))[0].shape}, labels- {next(iter(train_dl))[1].shape}\")\nprint(f\"val_dl batch shape: input- {next(iter(val_dl))[0].shape}, labels- {next(iter(val_dl))[1].shape}\")\nprint(f\"test_dl batch shape: input- {next(iter(test_dl))[0].shape}, labels- {len(next(iter(test_dl))[1])}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## define criterion, optimizer, scheduler and off we go for training #########\nLEARNING_RATE = 0.001\nNUM_EPOCHS = 35\n\n# criterion = RobustAsymmetricLoss(class_weights)\n# criterion = WeightedFocalLoss(CLASS_WEIGHTS, gamma=1.5)\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=7, verbose=True, min_lr=1e-6)\n\ntrained_model, weights = train_model(model, train_dl, val_dl, criterion, optimizer, NUM_EPOCHS, DEVICE, scheduler)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## saving the model and weights dict as a checkpoint\ncheckpoint = {\n    'model': trained_model,\n    'weights': weights\n}\ntorch.save(checkpoint, '/kaggle/working/checkpoint.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/working/checkpoint.pth')\ntrained_model = checkpoint['model'] #load trained model from checkpoint\n\nfinal_df = class_obj.get_final_df(trained_model, test_dl, device=DEVICE)\nfinal_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df.to_csv('/kaggle/working/final_NV_not_NV.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}